* Hadoop简介
1. 比较SQL数据库和Hadoop
   1) 用向外扩展代替向上扩展，（分布式系统，俗称向外扩展；大型单机服务器，俗称向上扩展）
   2) 用键/值对代替关系表，关系型数据库一个基本原则是让数据按照某种模式存放在具有关系型数据结构的表中。在Hadoop中，数据的来源可以有任何形式，但最终会转化为键/值对以供处理。
   3) 用函数式（MapReduce）代替声明式查询（SQL）。SQL查询数据的手段是，声明想要查询结果并让数据库引擎判定如何获取数据，在MapReduce中，实际的数据处理步骤是由用户指定。SQL使用查询语句，而MapReduce则使用脚本和代码。
   4) 用离线批量处理代替在线处理。Hadoop是专为离线处理和大规模数据分析而设计的，并不适合对几个记录随机读写在线事务处理模式。
2. MapReduce是一个数据处理模型，它最大的优点是容易扩展到多个计算节点上处理数据，在MapReduce模型中，数据处理原语被称为mapper和reducer。
3. MapReduce程序的执行分为两个主要阶段，为mapping和reducing。每个阶段均定义为一个数据处理函数，分别被称为mapper和reducer。在mapping阶段，MapReduce获取输入数据并将数据单元装入mapper。在reduceing阶段，reducer处理来自mapper的所有输出，并给出最终结果。简而言之，mapper意味着将输入进行过滤和转换，使reducer可以完成聚合。
  |        | 输入           | 输出           |
  |--------+----------------+----------------|
  | map    | <k1, v1>       | list(<k2, v2>) |
  | reduce | <k2, list(v2)> | list(<k3, v3>) |
4. 在MapReduce框架中编写应用程序就是定制化mapper和reducer的过程。
   1) 应用的输入必须组织为一个键/值对的列表list(<k2, v2>)。用于处理多个文集爱你的输入格式通常为list(<String filename, String file_content>)，用于处理日志文件这种大文件的输入格式为list(<Integer line_number, String log_event>)。
   2) 含有键/值对的列表被拆分，进而通过调用mapper的map函数对每个单独的键/值对<k1, v1>进行处理。在这里，键k1经常被mapper所忽略。mapper转换每个<k1, v1>对并将之放入<k2, v2>对的列表种。处理键/值对可以采用任意的顺序，而且，这种转换必须时封闭的，使得输出仅依赖于一个单独的键/值对。
   3) 所有mapper的输出(在概念上)被聚合到一个包含<k2, v2>对的巨大列表中。所有共享相同k2的对被组织在一起形成一个新的键/值对<k2, list(v2)>。框架让reducer来分别处理每个被聚合起来的<k2, list(v2)>。

* 初识Hadoop
1. 在一个全配置的集群上，“运行Hadoop”意味着在网络分布的不同服务器上运行一组守护进程(daemons)。这些守护进程有特殊的角色，一些存在单个服务器上，一些则运行在多个服务器上。它们包括：
   1. NameNode(名字节点)：Hadoop在分布式计算和分布式存储中都采用了主/从(master/slave)结构。分布式存储系统被称为Hadoop文件系统，或者简称HDFS。NameNode位于HDFS的主端，它指导从端的DataNode执行底层的I/O任务。NameNode跟踪文件如何被分割成文件块，而这些块又被哪些节点存储，以及分布式文件系统的整体运行状态是否正常。运行NameNode会消耗大量的内存和I/O资源。
   2. DataNode(数据节点):每一个集群上的从节点都会驻留一个DataNode守护进程，来执行分布式文件系统的繁重工作---将HDFS数据块读取或者写入到本地文件系统的实际文件中。
   3. Secondary NameNode(次名字节点)：用于监测HDFS集群状态的辅助守护进程。像NameNode一样，每个集群有一个SNN，它同常独占一台服务器，该服务器不会运行其他的DataNode或者TaskTracer守护进程。SNN与NameNode的不同在于它不接收或记录HDFS的任何实时变化。相反它与NameNode通信，根据集群所配置的时间间隔获取HDFS元数据的快照。
   4. JobTracker(作业跟踪节点)：JobTracker守护进程时应用程序和Hadoop之间的纽带。一旦提交代码到集群上，JobTracker就会确定执行计划。通常运行在服务器集群的主节点上。
   5. TaskTracker(任务跟踪节点):与存储的守护进程一样，计算的守护进程也遵循主/从架构：JobTracker作为主节点，检测MapReduce作业的整个执行过程，同时，TaskTracker管理各个任务在每个从节点上的执行情况。每个TaskTracker负责执行由JobTracker分配的单项任务。TaskTracker持续不断地与JobTracker通信。

* Hadoop组件
1. HDFS是一种文件系统，专为MapReduce这类框架下的大规模分布式数据处理而设计。
2. Hadoop的文件命令采取的形式为 hadoop fs -cmd <args>，其中cmd是具体的文件命令，而<args>是一组数目可变的参数，cmd的命令通常与UNIX对应的命令相同。
